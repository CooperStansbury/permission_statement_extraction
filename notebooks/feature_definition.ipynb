{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # here's how to get qt content in another notebook\n",
    "# %run 'hueristic_extraction.ipynb'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION:  3.7.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(\"VERSION: \", python_version()) # expect 3.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# zoomies\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn import decomposition, ensemble\n",
    "import xgboost,textblob, string\n",
    "\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras import layers, models, optimizers\n",
    "\n",
    "# custom data loading functions\n",
    "import load_data\n",
    "import clean_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION:  3.7.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(\"VERSION: \", python_version()) # expect 3.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty spaCy error workaround:\n",
    "get_ipython().config.get('IPKernelApp', {})['parent_appname'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = '../data/data_turk/dummy_data.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>370</td>\n",
       "      <td>/ my child has already had dtpa vaccination i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>490</td>\n",
       "      <td>all you have to do is tell us you want to stop.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>490</td>\n",
       "      <td>tufts medical center tufts university departme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>387</td>\n",
       "      <td>\"if you agree to being audiotaped but feel unc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>387</td>\n",
       "      <td>you will be given a copy of this form to keep ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.    370   \n",
       "1  NON_permission_statement.    490   \n",
       "2  NON_permission_statement.    490   \n",
       "3       permission_statement    387   \n",
       "4  NON_permission_statement.    387   \n",
       "\n",
       "                                                text  \n",
       "0  / my child has already had dtpa vaccination i ...  \n",
       "1    all you have to do is tell us you want to stop.  \n",
       "2  tufts medical center tufts university departme...  \n",
       "3  \"if you agree to being audiotaped but feel unc...  \n",
       "4  you will be given a copy of this form to keep ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data.getJSONData(test)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Labels to Binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "to  = 'label'\n",
    "field = 'annotation'\n",
    "    \n",
    "df[to] = df.apply(lambda row:clean_data.convertAnnotationtoBinary(row, field), axis =1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>370</td>\n",
       "      <td>/ my child has already had dtpa vaccination i ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>490</td>\n",
       "      <td>all you have to do is tell us you want to stop.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>490</td>\n",
       "      <td>tufts medical center tufts university departme...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>387</td>\n",
       "      <td>\"if you agree to being audiotaped but feel unc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>387</td>\n",
       "      <td>you will be given a copy of this form to keep ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.    370   \n",
       "1  NON_permission_statement.    490   \n",
       "2  NON_permission_statement.    490   \n",
       "3       permission_statement    387   \n",
       "4  NON_permission_statement.    387   \n",
       "\n",
       "                                                text  label  \n",
       "0  / my child has already had dtpa vaccination i ...      0  \n",
       "1    all you have to do is tell us you want to stop.      0  \n",
       "2  tufts medical center tufts university departme...      0  \n",
       "3  \"if you agree to being audiotaped but feel unc...      1  \n",
       "4  you will be given a copy of this form to keep ...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive class: 116\n",
      "total:  520\n",
      "ratio:  0.2230769230769231\n"
     ]
    }
   ],
   "source": [
    "print('positive class:', df['label'].sum())\n",
    "print('total: ', len(df))\n",
    "print('ratio: ', df['label'].sum()/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['char_count'] = df['text'].apply(len)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "df['word_density'] = df['char_count'] / (df['word_count']+1)\n",
    "df['punctuation_count'] = df['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## POS Counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_family = {\n",
    "    'noun' : ['NN','NNS','NNP','NNPS'],\n",
    "    'pron' : ['PRP','PRP$','WP','WP$'],\n",
    "    'verb' : ['VB','VBD','VBG','VBN','VBP','VBZ'],\n",
    "    'adj' :  ['JJ','JJR','JJS'],\n",
    "    'adv' : ['RB','RBR','RBS','WRB']\n",
    "}\n",
    "\n",
    "# function to check and get the part of speech tag count of a words in a given sentence\n",
    "def check_pos_tag(x, flag):\n",
    "    cnt = 0\n",
    "    try:\n",
    "        wiki = textblob.TextBlob(x)\n",
    "        for tup in wiki.tags:\n",
    "            ppo = list(tup)[1]\n",
    "            if ppo in pos_family[flag]:\n",
    "                cnt += 1\n",
    "    except:\n",
    "        pass\n",
    "    return cnt\n",
    "\n",
    "df['noun_count'] = df['text'].apply(lambda x: check_pos_tag(x, 'noun'))\n",
    "df['verb_count'] = df['text'].apply(lambda x: check_pos_tag(x, 'verb'))\n",
    "df['adj_count'] = df['text'].apply(lambda x: check_pos_tag(x, 'adj'))\n",
    "df['adv_count'] = df['text'].apply(lambda x: check_pos_tag(x, 'adv'))\n",
    "df['pron_count'] = df['text'].apply(lambda x: check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>textDOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>370</td>\n",
       "      <td>/ my child has already had dtpa vaccination i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>23</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>(/, my, child, has, already, had, dtpa, vaccin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>490</td>\n",
       "      <td>all you have to do is tell us you want to stop.</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(all, you, have, to, do, is, tell, us, you, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>490</td>\n",
       "      <td>tufts medical center tufts university departme...</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>32</td>\n",
       "      <td>6.484848</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(tufts, medical, center, tufts, university, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>387</td>\n",
       "      <td>\"if you agree to being audiotaped but feel unc...</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>24</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(\", if, you, agree, to, being, audiotaped, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>387</td>\n",
       "      <td>you will be given a copy of this form to keep ...</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>15</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(you, will, be, given, a, copy, of, this, form...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.    370   \n",
       "1  NON_permission_statement.    490   \n",
       "2  NON_permission_statement.    490   \n",
       "3       permission_statement    387   \n",
       "4  NON_permission_statement.    387   \n",
       "\n",
       "                                                text  label  char_count  \\\n",
       "0  / my child has already had dtpa vaccination i ...      0         117   \n",
       "1    all you have to do is tell us you want to stop.      0          47   \n",
       "2  tufts medical center tufts university departme...      0         214   \n",
       "3  \"if you agree to being audiotaped but feel unc...      1         136   \n",
       "4  you will be given a copy of this form to keep ...      0          67   \n",
       "\n",
       "   word_count  word_density  punctuation_count  noun_count  verb_count  \\\n",
       "0          23      4.875000                  1           8           8   \n",
       "1          12      3.615385                  1           0           6   \n",
       "2          32      6.484848                  4          15           6   \n",
       "3          24      5.440000                  4           5           4   \n",
       "4          15      4.187500                  1           3           3   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \\\n",
       "0          1          3           2   \n",
       "1          0          0           3   \n",
       "2          2          0           3   \n",
       "3          1          1           2   \n",
       "4          1          0           2   \n",
       "\n",
       "                                             textDOC  \n",
       "0  (/, my, child, has, already, had, dtpa, vaccin...  \n",
       "1  (all, you, have, to, do, is, tell, us, you, wa...  \n",
       "2  (tufts, medical, center, tufts, university, de...  \n",
       "3  (\", if, you, agree, to, being, audiotaped, but...  \n",
       "4  (you, will, be, given, a, copy, of, this, form...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to spaCy object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "nCores = cpu_count()\n",
    "print(nCores) # just 4 for my machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>textDOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>370</td>\n",
       "      <td>/ my child has already had dtpa vaccination i ...</td>\n",
       "      <td>0</td>\n",
       "      <td>117</td>\n",
       "      <td>23</td>\n",
       "      <td>4.875000</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>(/, my, child, has, already, had, dtpa, vaccin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>490</td>\n",
       "      <td>all you have to do is tell us you want to stop.</td>\n",
       "      <td>0</td>\n",
       "      <td>47</td>\n",
       "      <td>12</td>\n",
       "      <td>3.615385</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(all, you, have, to, do, is, tell, us, you, wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>490</td>\n",
       "      <td>tufts medical center tufts university departme...</td>\n",
       "      <td>0</td>\n",
       "      <td>214</td>\n",
       "      <td>32</td>\n",
       "      <td>6.484848</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>(tufts, medical, center, tufts, university, de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>387</td>\n",
       "      <td>\"if you agree to being audiotaped but feel unc...</td>\n",
       "      <td>1</td>\n",
       "      <td>136</td>\n",
       "      <td>24</td>\n",
       "      <td>5.440000</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>(\", if, you, agree, to, being, audiotaped, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>387</td>\n",
       "      <td>you will be given a copy of this form to keep ...</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>15</td>\n",
       "      <td>4.187500</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>(you, will, be, given, a, copy, of, this, form...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0  NON_permission_statement.    370   \n",
       "1  NON_permission_statement.    490   \n",
       "2  NON_permission_statement.    490   \n",
       "3       permission_statement    387   \n",
       "4  NON_permission_statement.    387   \n",
       "\n",
       "                                                text  label  char_count  \\\n",
       "0  / my child has already had dtpa vaccination i ...      0         117   \n",
       "1    all you have to do is tell us you want to stop.      0          47   \n",
       "2  tufts medical center tufts university departme...      0         214   \n",
       "3  \"if you agree to being audiotaped but feel unc...      1         136   \n",
       "4  you will be given a copy of this form to keep ...      0          67   \n",
       "\n",
       "   word_count  word_density  punctuation_count  noun_count  verb_count  \\\n",
       "0          23      4.875000                  1           8           8   \n",
       "1          12      3.615385                  1           0           6   \n",
       "2          32      6.484848                  4          15           6   \n",
       "3          24      5.440000                  4           5           4   \n",
       "4          15      4.187500                  1           3           3   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \\\n",
       "0          1          3           2   \n",
       "1          0          0           3   \n",
       "2          2          0           3   \n",
       "3          1          1           2   \n",
       "4          1          0           2   \n",
       "\n",
       "                                             textDOC  \n",
       "0  (/, my, child, has, already, had, dtpa, vaccin...  \n",
       "1  (all, you, have, to, do, is, tell, us, you, wa...  \n",
       "2  (tufts, medical, center, tufts, university, de...  \n",
       "3  (\", if, you, agree, to, being, audiotaped, but...  \n",
       "4  (you, will, be, given, a, copy, of, this, form...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertFrom = 'text'\n",
    "convertTo = 'textDOC'\n",
    "\n",
    "df[convertTo] = dd.from_pandas(df,npartitions=nCores).\\\n",
    "   map_partitions(\n",
    "      lambda df : df.apply(\n",
    "         lambda x :clean_data.getDocObjects(x, convertFrom),axis=1)).\\\n",
    "   compute(scheduler='threads')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- looks like vector is always the same size, while tensor is variable\n",
    "- noun_chunks look critical (perhaps for the next stage)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------\n",
      "noun_chunks:  [my child, dtpa vaccination, i, my child, only vaccine]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1957632766068182\n",
      "tensor.shape:  (23, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, us, you]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  4.019685360797594\n",
      "tensor.shape:  (13, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [research title, study principal investigator, we, you, part, a research study, we]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1050915619781208\n",
      "tensor.shape:  (37, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, any time, the interview, i, the recorder, your request]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.307398487308692\n",
      "tensor.shape:  (28, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, a copy, this form, your own records]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.704410080913383\n",
      "tensor.shape:  (16, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [compensation, information, payment, other types, compensation, method, timing, payment, you, this study, you, a $20 gift card, you, the interview]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.0437940659954026\n",
      "tensor.shape:  (55, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [no cost, you, part, this project]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.5831910918737995\n",
      "tensor.shape:  (13, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [order, the risk, unintended release, information, shared data, samples, all identifiers, a study code, tracking]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.185202038258624\n",
      "tensor.shape:  (33, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, other researchers, very professional alld, confidentiality, we, they, the same rules]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.277493046447053\n",
      "tensor.shape:  (31, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [they]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  4.093615754394454\n",
      "tensor.shape:  (8, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, disease, we, disease]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.7291864616252774\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, all information, the database]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.6890418955858464\n",
      "tensor.shape:  (10, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, coded data, these types, databases]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.63281055680755\n",
      "tensor.shape:  (11, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, this information, a research database]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.7639616203276116\n",
      "tensor.shape:  (10, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [researchers, information, you, any court matter]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.7721155619372517\n",
      "tensor.shape:  (18, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, the inside, the mouth, this swab, it]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4621261386333213\n",
      "tensor.shape:  (20, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [your/your child s consent, your/his/her authorization, we, you, dr]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1851965128127064\n",
      "tensor.shape:  (27, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [your surviving child]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.6280318028813436\n",
      "tensor.shape:  (9, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the irb, research, the risks, all studies]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1613434356642602\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, all available precautions, an infection, sterile technique]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.3072904214373793\n",
      "tensor.shape:  (18, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [she, what, the study, the possible risks, benefits, this study, what you/]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.3810240726448533\n",
      "tensor.shape:  (27, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the patient, she, the patient, children, his/her name]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.386243433274594\n",
      "tensor.shape:  (30, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [signature, parent, legal custody, legal guardian, date adult patient, emancipated minor patient, other legally authorized representative, patient  print name relationship, patient notary acknowledgment, this form, a children s location]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.0962507372042753\n",
      "tensor.shape:  (50, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, i, the information, i, i, the patient, i, the patient]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.2688609833661615\n",
      "tensor.shape:  (39, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, this agreement, my cancellation, my financial responsibility, the patient s care, children, my notice, cancellation]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.3425477789041556\n",
      "tensor.shape:  (36, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, i, children, all payment obligations, the medical care, services, supplies, ( care, the patient, the next year]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.179274896362789\n",
      "tensor.shape:  (39, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [example, information, samples, samples, key family members, some other problem, the sample, it, the testing lab, the samples, the neurome neurological exome test, the results, the test]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.181201644181582\n",
      "tensor.shape:  (77, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [information, the sample, some other problem, the sample, it, the testing laboratory, the sample, the site-specific genetic test, the results, the test]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.319573086800383\n",
      "tensor.shape:  (63, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [some instances, potential commercial value, the athena diagnostics, others]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1026703358753607\n",
      "tensor.shape:  (25, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [\"information, the reliability, positive or negative test results, the level, certainty, a positive test result, that disease, condition, a predictor, such disease]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.431749647781953\n",
      "tensor.shape:  (36, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, a family member, who, testing, evaluation, the patient s genetics, neither you, your physician, the results, the test]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.295697097305076\n",
      "tensor.shape:  (40, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, if|, any questions, this information, |wi||, kathy nordgren]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.6784723393315897\n",
      "tensor.shape:  (20, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [\"7. incomplete removal endoscopic ultrasound, fine needle aspirate, injection, fiducial placement]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.8421145931383935\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [risks, perforation, 2%, polyps, coagulation treatment]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.2440665406956835\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, representatives, companies, equipment, my procedures]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.6427201591657608\n",
      "tensor.shape:  (26, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, a bill, this study, dr]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.2916327705265753\n",
      "tensor.shape:  (16, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [addition, you, the findings, members, your family]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4270954549980717\n",
      "tensor.shape:  (23, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [this form, you, your legal rights]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.138680521883653\n",
      "tensor.shape:  (18, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the test, the sequencing, the patient, the full cost, the test]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.3025436033932953\n",
      "tensor.shape:  (25, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [[a24, the meaning, the results, this genetic research, we, you, the results, these studies]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.246790412210301\n",
      "tensor.shape:  (28, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  []\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.9396353432409574\n",
      "tensor.shape:  (5, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [this visit, we, some tests, procedures, you, part, this research study]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4819675812938966\n",
      "tensor.shape:  (26, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [many additional elements, your study, genetic testing, future use, specimens, certificate, confidentiality]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4250247452482707\n",
      "tensor.shape:  (31, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, i, my legal rights, this informed consent document]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.5336066360515046\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [this time, we, you, [number] study visits, [montefiore medical center/other locations]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.009749646603375\n",
      "tensor.shape:  (27, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the future, researchers, permission, the specimens/data, new studies, disease, genetic research]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.2484339418273005\n",
      "tensor.shape:  (32, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, a signed copy, this consent form]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.6298314193957033\n",
      "tensor.shape:  (12, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [a56]the subjects, diagnostic radiation, no therapeutic radiation, standard, care, part, the study, entire section]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1833790860727165\n",
      "tensor.shape:  (31, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, hospice, comfort, care.[a70, any consequences, me, i, this study]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1970510241671826\n",
      "tensor.shape:  (29, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  []\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  4.005417471467679\n",
      "tensor.shape:  (5, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [this assent document, (examples, children ages, adults, informed consent]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.837099569259492\n",
      "tensor.shape:  (30, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [name, participant  signature, participant  date, name, witness  signature, witness, date, [pi name, page, study, irb use, only version, 072012 image, stamp institution, approveddate expiration expirationdate number]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.3339905007460544\n",
      "tensor.shape:  (51, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [your participation, this research, you, benefits, you]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4646231096915514\n",
      "tensor.shape:  (29, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [my physician, me, written information, a genetic counselor, medical geneticist, whom, i, such counseling]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.463056412248135\n",
      "tensor.shape:  (23, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, my samples, future research]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.6061471476319285\n",
      "tensor.shape:  (10, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [it, this research study, your written authorization]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.434759893663092\n",
      "tensor.shape:  (18, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, you, this research study]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.671757340056813\n",
      "tensor.shape:  (20, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [this document, you, your right, legal action, all parties, this research]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.5972192602503745\n",
      "tensor.shape:  (25, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [study participants, placebos, the effects, a drug, no drug]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.6284728869352825\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [withdrawal, a child, the investigator, possible reasons]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.2951641018246987\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, your child, the study, you, an updated consent form]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.5002598934194356\n",
      "tensor.shape:  (26, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [this section, you, a witness, the consent process/signature]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.466722144541179\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [single blind trial, a blind trial, you, which treatment group, your child]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.484288675531242\n",
      "tensor.shape:  (20, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, your child, an injury, a result, this research program, the investigators, chief, staff, shriners hospitals, children, salt lake city hospital]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.883903171869311\n",
      "tensor.shape:  (50, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, this entire form]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.76716066245052\n",
      "tensor.shape:  (7, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [this form, me, the information, i, a good decision, it, me]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.603656982209157\n",
      "tensor.shape:  (26, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, it, it, additional post-operative, x-rays, injections, anesthetics, any complications]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1296110350827195\n",
      "tensor.shape:  (35, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, deductibles, the time services, all costs, my insurance, 45 days]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.293231505251186\n",
      "tensor.shape:  (33, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, the procedure, the healing process, i, any drugs, my doctor]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4217750773618523\n",
      "tensor.shape:  (29, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [your genetic information, ways, you, your family distress, you, a relative, a genetic disease, the denial, employment, insurance, you, a relative]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.3321907721418715\n",
      "tensor.shape:  (55, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [many different kinds, cancer, this way, we, the genetic changes, different kinds, cancer]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4501792771804682\n",
      "tensor.shape:  (29, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [new york city health and hospitals corporation, consent, hiv test new york state department, health aids, institute name ward]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4460343472444936\n",
      "tensor.shape:  (25, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, information, we, our research, the integrity, the research]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.472569132341578\n",
      "tensor.shape:  (30, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the participant, this research, this study, the problem]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.588091206001832\n",
      "tensor.shape:  (19, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [we, any benefits, your child, your being, the study]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.5783650808454395\n",
      "tensor.shape:  (17, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [addition, the debriefing script, participants, the need, deception, the procedures, you, any possible adverse effects, the deception]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.270331948053349\n",
      "tensor.shape:  (37, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [testing, a result, study participation, any communicable or infectious diseases, utah state law, the following, this section, a current list, utah s reportable diseases, the participant, the state reporting]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.964642701739469\n",
      "tensor.shape:  (56, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, i, a witness, the consent process, this study]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.5226365648616427\n",
      "tensor.shape:  (17, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [investigator version date] footer, irb use, only version, 102513 image, stamp institution, approveddate expiration expirationdate number]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.4627701570183946\n",
      "tensor.shape:  (29, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, this experience, you, the researcher, he, she, you, resources]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4702223750174483\n",
      "tensor.shape:  (29, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the application, you, a waiver, alteration, consent, the electronic application]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.3236792270211026\n",
      "tensor.shape:  (20, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, someone, who, this project, questions, your rights, a research subject, the office, the protection, research subjects]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4246690587442163\n",
      "tensor.shape:  (40, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, your consent, it]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4508827521742984\n",
      "tensor.shape:  (13, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [signature, child date, name, child signature, parent, date, printed name, parent, the child s consent, the child s general medical care general medical care, note]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4904675375159346\n",
      "tensor.shape:  (60, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [all cases, information, your sample and health information, the people, groups, you, a unique number, name, social security number, address, telephone number, any direct identifier, law]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.349279815043168\n",
      "tensor.shape:  (56, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [signature, parent date, name, parent, signature, second parent, the irb, the permission, one second parent, incompetent parent, sufficient second parent, reasonably available second parent, only one parent, legal responsibility second parent, the care, custody, the child, signature]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.2427443556390325\n",
      "tensor.shape:  (73, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, dentures, teeth, no teeth]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4732195636445358\n",
      "tensor.shape:  (24, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the college, dentistry, the best job, they, the oral condition, my mouth]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.4777402677606792\n",
      "tensor.shape:  (22, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [i, i, a reline or denture remake, it, the continued physiologic bone resorption, the ridge, the average denture, a laboratory reline, functional wear, continued bone resorption]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.023133306110362\n",
      "tensor.shape:  (53, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the protocol director, your participation, you]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.364753720627173\n",
      "tensor.shape:  (15, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [investigators, the appropriate provisions, their informed consent form, the following language]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.5771918308566932\n",
      "tensor.shape:  (25, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, any questions, concerns, complaints, this research study, its procedures, risks, benefits, alternative courses, treatment, you, the protocol director, name, protocol director]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1953047367978655\n",
      "tensor.shape:  (44, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [you, him, her, any time, you, you, a part, this study]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.6356075191785235\n",
      "tensor.shape:  (25, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [an explanation, the procedures, the medical experiment, a description, any attendant discomforts, risks, an explanation, any benefits, the subject]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.2962090878914903\n",
      "tensor.shape:  (62, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [a specific date, the authorization, december]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  2.9879708795510465\n",
      "tensor.shape:  (28, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the information, the least amount, information, the purpose, the research, (i.e., information, a particular medical condition, specific blood tests, specific physical examination measures, specific x-rays or mri imaging information, any reports, radiology or pathology reports, who, the information, the following parties, your health information, connection, this research study, the protocol director, name, pd]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.1527609786589967\n",
      "tensor.shape:  (98, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [\"if applicable: appointment contact, you, your appointment, (name, phone number]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.267188297168353\n",
      "tensor.shape:  (27, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [the stanford university administrative panel, human subjects, medical research, any other unit, stanford university, necessary * research staff, every other class, persons, organization, stanford, who, the participant's information, connection, this study, who, the information, the parties, the preceding paragraph, your health information, the following persons, organizations, their use, connection, this research study, the office, human research protections, the u.s]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.24354440207834\n",
      "tensor.shape:  (100, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [people, problems, research studies, them]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.9422232477552432\n",
      "tensor.shape:  (13, 384)\n",
      "\n",
      "------\n",
      "noun_chunks:  [it, the researchers, your parents, anything, you, the research study]\n",
      "vector.shape:  (300,)\n",
      "vector_norm:  3.791424761591343\n",
      "tensor.shape:  (27, 384)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for sent in df['textDOC'].head(100):\n",
    "    print('------')\n",
    "#     print(sent.ents)\n",
    "    print('noun_chunks: ', list(sent.noun_chunks))\n",
    "#     print('vocab: ', sent.vocab)\n",
    "#     print('vector: ', sent.vector)\n",
    "    print('vector.shape: ', sent.vector.shape)\n",
    "    print('vector_norm: ', sent.vector_norm)\n",
    "    print('tensor.shape: ', sent.tensor.shape)\n",
    "#     print(dir(sent))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count Vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a count vectorizer object \n",
    "# count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}')\n",
    "# count_vect_fit = count_vect.fit_transform(df['text'])\n",
    "\n",
    "# count_vec_df = pd.DataFrame(data=count_vect_fit.toarray()[0:,0:], \n",
    "#                          columns = count_vect.get_feature_names())\n",
    "\n",
    "# df = pd.concat([df, count_vec_df], axis=1, sort=False)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # create a count vectorizer object \n",
    "# tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "# tfidf_vec = tfidf_vect.fit_transform(df['text'])\n",
    "\n",
    "# tfidf_df = pd.DataFrame(data=tfidf_vec.toarray()[0:,0:], \n",
    "#                          columns = count_vect.get_feature_names())\n",
    "\n",
    "# df = pd.concat([df, tfidf_df], axis=1, sort=False)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # label encode the target variable \n",
    "# encoder = preprocessing.LabelEncoder()\n",
    "# train_y = encoder.fit_transform(train_y)\n",
    "# valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ngram level tf-idf \n",
    "# tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "# tfidf_vect_ngram.fit(df['text'])\n",
    "# xtrain_tfidf_ngram =  tfidf_vect_ngram.transform(train_x)\n",
    "# xvalid_tfidf_ngram =  tfidf_vect_ngram.transform(valid_x)\n",
    "\n",
    "# # characters level tf-idf\n",
    "# tfidf_vect_ngram_chars = TfidfVectorizer(analyzer='char', token_pattern=r'\\w{1,}', ngram_range=(2,3), max_features=5000)\n",
    "# tfidf_vect_ngram_chars.fit(df['text'])\n",
    "# xtrain_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(train_x) \n",
    "# xvalid_tfidf_ngram_chars =  tfidf_vect_ngram_chars.transform(valid_x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # split the dataset into training and validation datasets \n",
    "# train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df['text'], df['label'],\n",
    "#                                                                      test_size=.2,\n",
    "#                                                                      random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # train a LDA Model\n",
    "# lda_model = decomposition.LatentDirichletAllocation(n_components=20, learning_method='online', max_iter=20)\n",
    "# X_topics = lda_model.fit_transform(xtrain_count)\n",
    "# topic_word = lda_model.components_ \n",
    "# vocab = count_vect.get_feature_names()\n",
    "\n",
    "# # view the topic models\n",
    "# n_top_words = 10\n",
    "# topic_summaries = []\n",
    "# for i, topic_dist in enumerate(topic_word):\n",
    "#     topic_words = numpy.array(vocab)[numpy.argsort(topic_dist)][:-(n_top_words+1):-1]\n",
    "#     topic_summaries.append(' '.join(topic_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "# ## NOTE: \n",
    "# `minTermFrequencyThreshold = 0` will result in all \n",
    "# possible n_grams and will not scale as input size or \n",
    "# ngramSize increases. However, it is the most robust \n",
    "# representation of the sentence, and is worth exploring for the time being...\n",
    "# \"\"\"\n",
    "\n",
    "# ngramSize = 5\n",
    "# maxTermFrequencyThreshold = .8\n",
    "# minTermFrequencyThreshold = .001\n",
    "\n",
    "# def getTDIDFMatrix(corpus, ngram_range, max_df, min_df):\n",
    "#     \"\"\" return td-idf matrix and terms \"\"\"\n",
    "    \n",
    "#     tfidf_vectorizer = TfidfVectorizer(use_idf=True, \n",
    "#                                        ngram_range=(1,ngram_range),\n",
    "#                                        max_df=max_df,min_df=min_df)\n",
    "    \n",
    "#     tfidf_matrix = tfidf_vectorizer.fit_transform(corpus)\n",
    "#     terms = tfidf_vectorizer.get_feature_names()\n",
    "    \n",
    "#     return tfidf_matrix, terms\n",
    "\n",
    "# # save to a variable \n",
    "# tdidf_matrix, tdidf_terms = getTDIDFMatrix(corpus, \n",
    "#                                            ngramSize, \n",
    "#                                            maxTermFrequencyThreshold,\n",
    "#                                            minTermFrequencyThreshold)\n",
    "\n",
    "# # # print tests\n",
    "# # print('\\nfirst few terms:')\n",
    "# # [print(\" \", x) for x in tdidf_terms[:10]]\n",
    "\n",
    "# print('\\nNumber of terms:', len(tdidf_terms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
