{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Two subgroups of code:\n",
    "1. Featuere Extraction from the Annotations (Data Turk)\n",
    "1. Train classifiers based on Featuere Extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERSION:  3.7.0\n"
     ]
    }
   ],
   "source": [
    "from platform import python_version\n",
    "print(\"VERSION: \", python_version()) # expect 3.7.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "from importlib import reload\n",
    "\n",
    "# zoomies\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "from multiprocessing import cpu_count\n",
    "\n",
    "# custom data loading functions\n",
    "import load_data\n",
    "import clean_data\n",
    "import custom_feature_extraction\n",
    "import custom_keras_metrics\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "from tensorflow.metrics import auc as tf_auc\n",
    "from tensorflow import local_variables_initializer\n",
    "import keras\n",
    "import keras.backend as K\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, \\\n",
    "        MaxPooling1D, LSTM, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dirty spaCy error workaround:\n",
    "get_ipython().config.get('IPKernelApp', {})['parent_appname'] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations ='../data/data_turk/Annotations04-05-19.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>i give my permission for photographs/audio/vid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"(if applicable, add) information about indivi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>this consent form will be filed securely in an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"[include circumstances, if any, where partial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"i hereby certify that to the best of my knowl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0       permission_statement      1   \n",
       "1  NON_permission_statement.      1   \n",
       "2  NON_permission_statement.      1   \n",
       "3  NON_permission_statement.      1   \n",
       "4       permission_statement      1   \n",
       "\n",
       "                                                text  \n",
       "0  i give my permission for photographs/audio/vid...  \n",
       "1  \"(if applicable, add) information about indivi...  \n",
       "2  this consent form will be filed securely in an...  \n",
       "3  \"[include circumstances, if any, where partial...  \n",
       "4  \"i hereby certify that to the best of my knowl...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(load_data)\n",
    "df = load_data.getJSONData(annotations)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Class Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "to  = 'label'\n",
    "field = 'annotation'\n",
    "    \n",
    "df[to] = df.apply(lambda row:clean_data.convertAnnotationtoBinary(row, field), axis =1)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive class: 579\n",
      "total:  2468\n",
      "total unique:  2343\n",
      "ratio:  0.2346029173419773\n"
     ]
    }
   ],
   "source": [
    "# quick summary of the data \n",
    "print('positive class:', df['label'].sum())\n",
    "print('total: ', len(df))\n",
    "print('total unique: ', len(set(df['text'])))\n",
    "print('ratio: ', df['label'].sum()/len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Count Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['char_count'] = df['text'].apply(len)\n",
    "df['word_count'] = df['text'].apply(lambda x: len(x.split()))\n",
    "df['word_density'] = df['char_count'] / (df['word_count']+1)\n",
    "df['punctuation_count'] = df['text'].apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['noun_count'] = df['text'].apply(lambda x: custom_feature_extraction.check_pos_tag(x, 'noun'))\n",
    "df['verb_count'] = df['text'].apply(lambda x: custom_feature_extraction.check_pos_tag(x, 'verb'))\n",
    "df['adj_count'] = df['text'].apply(lambda x: custom_feature_extraction.check_pos_tag(x, 'adj'))\n",
    "df['adv_count'] = df['text'].apply(lambda x: custom_feature_extraction.check_pos_tag(x, 'adv'))\n",
    "df['pron_count'] = df['text'].apply(lambda x: custom_feature_extraction.check_pos_tag(x, 'pron'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "nCores = cpu_count()\n",
    "print(nCores) # just 4 for my machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Raw Text to spaCy for more feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>textDOC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>i give my permission for photographs/audio/vid...</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>19</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(i, give, my, permission, for, photographs, /,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"(if applicable, add) information about indivi...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>23</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", (, if, applicable, ,, add, ), information,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>this consent form will be filed securely in an...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(this, consent, form, will, be, filed, securel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"[include circumstances, if any, where partial...</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>37</td>\n",
       "      <td>5.684211</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", [, include, circumstances, ,, if, any, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"i hereby certify that to the best of my knowl...</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>31</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", i, hereby, certify, that, to, the, best, o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0       permission_statement      1   \n",
       "1  NON_permission_statement.      1   \n",
       "2  NON_permission_statement.      1   \n",
       "3  NON_permission_statement.      1   \n",
       "4       permission_statement      1   \n",
       "\n",
       "                                                text  label  char_count  \\\n",
       "0  i give my permission for photographs/audio/vid...      1         124   \n",
       "1  \"(if applicable, add) information about indivi...      0         144   \n",
       "2  this consent form will be filed securely in an...      0          61   \n",
       "3  \"[include circumstances, if any, where partial...      0         216   \n",
       "4  \"i hereby certify that to the best of my knowl...      1         186   \n",
       "\n",
       "   word_count  word_density  punctuation_count  noun_count  verb_count  \\\n",
       "0          19      6.200000                  3           0           0   \n",
       "1          23      6.000000                  7           0           0   \n",
       "2          11      5.083333                  1           0           0   \n",
       "3          37      5.684211                  7           0           0   \n",
       "4          31      5.812500                  7           0           0   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \\\n",
       "0          0          0           0   \n",
       "1          0          0           0   \n",
       "2          0          0           0   \n",
       "3          0          0           0   \n",
       "4          0          0           0   \n",
       "\n",
       "                                             textDOC  \n",
       "0  (i, give, my, permission, for, photographs, /,...  \n",
       "1  (\", (, if, applicable, ,, add, ), information,...  \n",
       "2  (this, consent, form, will, be, filed, securel...  \n",
       "3  (\", [, include, circumstances, ,, if, any, ,, ...  \n",
       "4  (\", i, hereby, certify, that, to, the, best, o...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convertFrom = 'text'\n",
    "convertTo = 'textDOC'\n",
    "\n",
    "df[convertTo] = dd.from_pandas(df,npartitions=nCores).\\\n",
    "   map_partitions(\n",
    "      lambda df : df.apply(\n",
    "         lambda x :clean_data.getDocObjects(x, convertFrom),axis=1)).\\\n",
    "   compute(scheduler='threads')\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Vectors\n",
    "https://spacy.io/usage/vectors-similarity\n",
    "\n",
    "[1] Models for the spaCy Natural Language Processing (NLP) library: explosion/spacy-models. Explosion, 2019.\n",
    "\n",
    "_\"English multi-task CNN trained on OntoNotes, with GloVe vectors trained on Common Crawl. Assigns word vectors, context-specific token vectors, POS tags, dependency parse and named entities.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>textDOC</th>\n",
       "      <th>sent_vec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>i give my permission for photographs/audio/vid...</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>19</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(i, give, my, permission, for, photographs, /,...</td>\n",
       "      <td>[-0.029749835, 0.12945084, -0.16006051, 0.0601...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"(if applicable, add) information about indivi...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>23</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", (, if, applicable, ,, add, ), information,...</td>\n",
       "      <td>[-0.064744644, 0.179507, -0.275384, -0.0227434...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>this consent form will be filed securely in an...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(this, consent, form, will, be, filed, securel...</td>\n",
       "      <td>[0.0638755, -0.007266668, -0.09555017, 0.10957...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"[include circumstances, if any, where partial...</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>37</td>\n",
       "      <td>5.684211</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", [, include, circumstances, ,, if, any, ,, ...</td>\n",
       "      <td>[-0.14210404, 0.21598653, -0.22471203, -0.0546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"i hereby certify that to the best of my knowl...</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>31</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", i, hereby, certify, that, to, the, best, o...</td>\n",
       "      <td>[-0.020474927, 0.16413753, -0.1526114, -0.0300...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0       permission_statement      1   \n",
       "1  NON_permission_statement.      1   \n",
       "2  NON_permission_statement.      1   \n",
       "3  NON_permission_statement.      1   \n",
       "4       permission_statement      1   \n",
       "\n",
       "                                                text  label  char_count  \\\n",
       "0  i give my permission for photographs/audio/vid...      1         124   \n",
       "1  \"(if applicable, add) information about indivi...      0         144   \n",
       "2  this consent form will be filed securely in an...      0          61   \n",
       "3  \"[include circumstances, if any, where partial...      0         216   \n",
       "4  \"i hereby certify that to the best of my knowl...      1         186   \n",
       "\n",
       "   word_count  word_density  punctuation_count  noun_count  verb_count  \\\n",
       "0          19      6.200000                  3           0           0   \n",
       "1          23      6.000000                  7           0           0   \n",
       "2          11      5.083333                  1           0           0   \n",
       "3          37      5.684211                  7           0           0   \n",
       "4          31      5.812500                  7           0           0   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \\\n",
       "0          0          0           0   \n",
       "1          0          0           0   \n",
       "2          0          0           0   \n",
       "3          0          0           0   \n",
       "4          0          0           0   \n",
       "\n",
       "                                             textDOC  \\\n",
       "0  (i, give, my, permission, for, photographs, /,...   \n",
       "1  (\", (, if, applicable, ,, add, ), information,...   \n",
       "2  (this, consent, form, will, be, filed, securel...   \n",
       "3  (\", [, include, circumstances, ,, if, any, ,, ...   \n",
       "4  (\", i, hereby, certify, that, to, the, best, o...   \n",
       "\n",
       "                                            sent_vec  \n",
       "0  [-0.029749835, 0.12945084, -0.16006051, 0.0601...  \n",
       "1  [-0.064744644, 0.179507, -0.275384, -0.0227434...  \n",
       "2  [0.0638755, -0.007266668, -0.09555017, 0.10957...  \n",
       "3  [-0.14210404, 0.21598653, -0.22471203, -0.0546...  \n",
       "4  [-0.020474927, 0.16413753, -0.1526114, -0.0300...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(custom_feature_extraction)\n",
    "\n",
    "df['sent_vec'] = df.apply(lambda row: custom_feature_extraction.getSentenceVectors(row), axis=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Noun_Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>pron_count</th>\n",
       "      <th>textDOC</th>\n",
       "      <th>sent_vec</th>\n",
       "      <th>noun_chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>i give my permission for photographs/audio/vid...</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>19</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(i, give, my, permission, for, photographs, /,...</td>\n",
       "      <td>[-0.029749835, 0.12945084, -0.16006051, 0.0601...</td>\n",
       "      <td>[i, my permission, photographs/audio/video rec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"(if applicable, add) information about indivi...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>23</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", (, if, applicable, ,, add, ), information,...</td>\n",
       "      <td>[-0.064744644, 0.179507, -0.275384, -0.0227434...</td>\n",
       "      <td>[information, individuals, organizations, you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>this consent form will be filed securely in an...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(this, consent, form, will, be, filed, securel...</td>\n",
       "      <td>[0.0638755, -0.007266668, -0.09555017, 0.10957...</td>\n",
       "      <td>[this consent form, an official area]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"[include circumstances, if any, where partial...</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>37</td>\n",
       "      <td>5.684211</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", [, include, circumstances, ,, if, any, ,, ...</td>\n",
       "      <td>[-0.14210404, 0.21598653, -0.22471203, -0.0546...</td>\n",
       "      <td>[circumstances, partial payment, no payment, i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"i hereby certify that to the best of my knowl...</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>31</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>(\", i, hereby, certify, that, to, the, best, o...</td>\n",
       "      <td>[-0.020474927, 0.16413753, -0.1526114, -0.0300...</td>\n",
       "      <td>[i, my knowledge, the person, who, this consen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0       permission_statement      1   \n",
       "1  NON_permission_statement.      1   \n",
       "2  NON_permission_statement.      1   \n",
       "3  NON_permission_statement.      1   \n",
       "4       permission_statement      1   \n",
       "\n",
       "                                                text  label  char_count  \\\n",
       "0  i give my permission for photographs/audio/vid...      1         124   \n",
       "1  \"(if applicable, add) information about indivi...      0         144   \n",
       "2  this consent form will be filed securely in an...      0          61   \n",
       "3  \"[include circumstances, if any, where partial...      0         216   \n",
       "4  \"i hereby certify that to the best of my knowl...      1         186   \n",
       "\n",
       "   word_count  word_density  punctuation_count  noun_count  verb_count  \\\n",
       "0          19      6.200000                  3           0           0   \n",
       "1          23      6.000000                  7           0           0   \n",
       "2          11      5.083333                  1           0           0   \n",
       "3          37      5.684211                  7           0           0   \n",
       "4          31      5.812500                  7           0           0   \n",
       "\n",
       "   adj_count  adv_count  pron_count  \\\n",
       "0          0          0           0   \n",
       "1          0          0           0   \n",
       "2          0          0           0   \n",
       "3          0          0           0   \n",
       "4          0          0           0   \n",
       "\n",
       "                                             textDOC  \\\n",
       "0  (i, give, my, permission, for, photographs, /,...   \n",
       "1  (\", (, if, applicable, ,, add, ), information,...   \n",
       "2  (this, consent, form, will, be, filed, securel...   \n",
       "3  (\", [, include, circumstances, ,, if, any, ,, ...   \n",
       "4  (\", i, hereby, certify, that, to, the, best, o...   \n",
       "\n",
       "                                            sent_vec  \\\n",
       "0  [-0.029749835, 0.12945084, -0.16006051, 0.0601...   \n",
       "1  [-0.064744644, 0.179507, -0.275384, -0.0227434...   \n",
       "2  [0.0638755, -0.007266668, -0.09555017, 0.10957...   \n",
       "3  [-0.14210404, 0.21598653, -0.22471203, -0.0546...   \n",
       "4  [-0.020474927, 0.16413753, -0.1526114, -0.0300...   \n",
       "\n",
       "                                         noun_chunks  \n",
       "0  [i, my permission, photographs/audio/video rec...  \n",
       "1  [information, individuals, organizations, you,...  \n",
       "2              [this consent form, an official area]  \n",
       "3  [circumstances, partial payment, no payment, i...  \n",
       "4  [i, my knowledge, the person, who, this consen...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['noun_chunks'] = df.apply(lambda row: custom_feature_extraction.getNounChunks(row), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'custom_feature_extraction' from '/Users/milk/Desktop/git/permission_statement_extraction/notebooks/custom_feature_extraction.py'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reload(custom_feature_extraction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert chunks to one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = custom_feature_extraction.convertNounChunkstoOneHot(df)\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert embeddings to one hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>annotation</th>\n",
       "      <th>fileID</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_posi290</th>\n",
       "      <th>vec_posi291</th>\n",
       "      <th>vec_posi292</th>\n",
       "      <th>vec_posi293</th>\n",
       "      <th>vec_posi294</th>\n",
       "      <th>vec_posi295</th>\n",
       "      <th>vec_posi296</th>\n",
       "      <th>vec_posi297</th>\n",
       "      <th>vec_posi298</th>\n",
       "      <th>vec_posi299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>i give my permission for photographs/audio/vid...</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>19</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236962</td>\n",
       "      <td>0.049824</td>\n",
       "      <td>0.063998</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>0.165136</td>\n",
       "      <td>-0.012342</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>0.058096</td>\n",
       "      <td>-0.013941</td>\n",
       "      <td>0.123927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"(if applicable, add) information about indivi...</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>23</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268256</td>\n",
       "      <td>0.110001</td>\n",
       "      <td>-0.037784</td>\n",
       "      <td>-0.066260</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>-0.105688</td>\n",
       "      <td>-0.123062</td>\n",
       "      <td>-0.156906</td>\n",
       "      <td>0.128169</td>\n",
       "      <td>0.060226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>this consent form will be filed securely in an...</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166543</td>\n",
       "      <td>0.088511</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>-0.265956</td>\n",
       "      <td>0.026951</td>\n",
       "      <td>-0.099905</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>-0.014592</td>\n",
       "      <td>0.047887</td>\n",
       "      <td>0.186848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NON_permission_statement.</td>\n",
       "      <td>1</td>\n",
       "      <td>\"[include circumstances, if any, where partial...</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>37</td>\n",
       "      <td>5.684211</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190944</td>\n",
       "      <td>0.043685</td>\n",
       "      <td>-0.074062</td>\n",
       "      <td>-0.096643</td>\n",
       "      <td>0.058032</td>\n",
       "      <td>-0.028758</td>\n",
       "      <td>-0.141962</td>\n",
       "      <td>-0.111375</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.044907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>permission_statement</td>\n",
       "      <td>1</td>\n",
       "      <td>\"i hereby certify that to the best of my knowl...</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>31</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160743</td>\n",
       "      <td>0.076126</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>-0.084644</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.035661</td>\n",
       "      <td>0.044390</td>\n",
       "      <td>0.051542</td>\n",
       "      <td>0.043067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6656 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  annotation fileID  \\\n",
       "0       permission_statement      1   \n",
       "1  NON_permission_statement.      1   \n",
       "2  NON_permission_statement.      1   \n",
       "3  NON_permission_statement.      1   \n",
       "4       permission_statement      1   \n",
       "\n",
       "                                                text  label  char_count  \\\n",
       "0  i give my permission for photographs/audio/vid...      1         124   \n",
       "1  \"(if applicable, add) information about indivi...      0         144   \n",
       "2  this consent form will be filed securely in an...      0          61   \n",
       "3  \"[include circumstances, if any, where partial...      0         216   \n",
       "4  \"i hereby certify that to the best of my knowl...      1         186   \n",
       "\n",
       "   word_count  word_density  punctuation_count  noun_count  verb_count  ...  \\\n",
       "0          19      6.200000                  3           0           0  ...   \n",
       "1          23      6.000000                  7           0           0  ...   \n",
       "2          11      5.083333                  1           0           0  ...   \n",
       "3          37      5.684211                  7           0           0  ...   \n",
       "4          31      5.812500                  7           0           0  ...   \n",
       "\n",
       "   vec_posi290  vec_posi291  vec_posi292 vec_posi293 vec_posi294  vec_posi295  \\\n",
       "0    -0.236962     0.049824     0.063998   -0.000753    0.165136    -0.012342   \n",
       "1    -0.268256     0.110001    -0.037784   -0.066260    0.008676    -0.105688   \n",
       "2    -0.166543     0.088511     0.055470   -0.265956    0.026951    -0.099905   \n",
       "3    -0.190944     0.043685    -0.074062   -0.096643    0.058032    -0.028758   \n",
       "4    -0.160743     0.076126     0.034459   -0.084644    0.055868     0.013227   \n",
       "\n",
       "   vec_posi296  vec_posi297  vec_posi298  vec_posi299  \n",
       "0     0.015370     0.058096    -0.013941     0.123927  \n",
       "1    -0.123062    -0.156906     0.128169     0.060226  \n",
       "2     0.018878    -0.014592     0.047887     0.186848  \n",
       "3    -0.141962    -0.111375     0.104723     0.044907  \n",
       "4     0.035661     0.044390     0.051542     0.043067  \n",
       "\n",
       "[5 rows x 6656 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = custom_feature_extraction.convertVectoOneHot(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop Columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_drop = [\n",
    "    'text',\n",
    "    'annotation',\n",
    "    'sent_vec',\n",
    "    'textDOC'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fileID</th>\n",
       "      <th>label</th>\n",
       "      <th>char_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>word_density</th>\n",
       "      <th>punctuation_count</th>\n",
       "      <th>noun_count</th>\n",
       "      <th>verb_count</th>\n",
       "      <th>adj_count</th>\n",
       "      <th>adv_count</th>\n",
       "      <th>...</th>\n",
       "      <th>vec_posi290</th>\n",
       "      <th>vec_posi291</th>\n",
       "      <th>vec_posi292</th>\n",
       "      <th>vec_posi293</th>\n",
       "      <th>vec_posi294</th>\n",
       "      <th>vec_posi295</th>\n",
       "      <th>vec_posi296</th>\n",
       "      <th>vec_posi297</th>\n",
       "      <th>vec_posi298</th>\n",
       "      <th>vec_posi299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>124</td>\n",
       "      <td>19</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236962</td>\n",
       "      <td>0.049824</td>\n",
       "      <td>0.063998</td>\n",
       "      <td>-0.000753</td>\n",
       "      <td>0.165136</td>\n",
       "      <td>-0.012342</td>\n",
       "      <td>0.015370</td>\n",
       "      <td>0.058096</td>\n",
       "      <td>-0.013941</td>\n",
       "      <td>0.123927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>23</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268256</td>\n",
       "      <td>0.110001</td>\n",
       "      <td>-0.037784</td>\n",
       "      <td>-0.066260</td>\n",
       "      <td>0.008676</td>\n",
       "      <td>-0.105688</td>\n",
       "      <td>-0.123062</td>\n",
       "      <td>-0.156906</td>\n",
       "      <td>0.128169</td>\n",
       "      <td>0.060226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>11</td>\n",
       "      <td>5.083333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.166543</td>\n",
       "      <td>0.088511</td>\n",
       "      <td>0.055470</td>\n",
       "      <td>-0.265956</td>\n",
       "      <td>0.026951</td>\n",
       "      <td>-0.099905</td>\n",
       "      <td>0.018878</td>\n",
       "      <td>-0.014592</td>\n",
       "      <td>0.047887</td>\n",
       "      <td>0.186848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>216</td>\n",
       "      <td>37</td>\n",
       "      <td>5.684211</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.190944</td>\n",
       "      <td>0.043685</td>\n",
       "      <td>-0.074062</td>\n",
       "      <td>-0.096643</td>\n",
       "      <td>0.058032</td>\n",
       "      <td>-0.028758</td>\n",
       "      <td>-0.141962</td>\n",
       "      <td>-0.111375</td>\n",
       "      <td>0.104723</td>\n",
       "      <td>0.044907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>186</td>\n",
       "      <td>31</td>\n",
       "      <td>5.812500</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.160743</td>\n",
       "      <td>0.076126</td>\n",
       "      <td>0.034459</td>\n",
       "      <td>-0.084644</td>\n",
       "      <td>0.055868</td>\n",
       "      <td>0.013227</td>\n",
       "      <td>0.035661</td>\n",
       "      <td>0.044390</td>\n",
       "      <td>0.051542</td>\n",
       "      <td>0.043067</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6651 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  fileID  label  char_count  word_count  word_density  punctuation_count  \\\n",
       "0      1      1         124          19      6.200000                  3   \n",
       "1      1      0         144          23      6.000000                  7   \n",
       "2      1      0          61          11      5.083333                  1   \n",
       "3      1      0         216          37      5.684211                  7   \n",
       "4      1      1         186          31      5.812500                  7   \n",
       "\n",
       "   noun_count  verb_count  adj_count  adv_count  ...  vec_posi290  \\\n",
       "0           0           0          0          0  ...    -0.236962   \n",
       "1           0           0          0          0  ...    -0.268256   \n",
       "2           0           0          0          0  ...    -0.166543   \n",
       "3           0           0          0          0  ...    -0.190944   \n",
       "4           0           0          0          0  ...    -0.160743   \n",
       "\n",
       "   vec_posi291  vec_posi292  vec_posi293  vec_posi294  vec_posi295  \\\n",
       "0     0.049824     0.063998    -0.000753     0.165136    -0.012342   \n",
       "1     0.110001    -0.037784    -0.066260     0.008676    -0.105688   \n",
       "2     0.088511     0.055470    -0.265956     0.026951    -0.099905   \n",
       "3     0.043685    -0.074062    -0.096643     0.058032    -0.028758   \n",
       "4     0.076126     0.034459    -0.084644     0.055868     0.013227   \n",
       "\n",
       "   vec_posi296  vec_posi297  vec_posi298  vec_posi299  \n",
       "0     0.015370     0.058096    -0.013941     0.123927  \n",
       "1    -0.123062    -0.156906     0.128169     0.060226  \n",
       "2     0.018878    -0.014592     0.047887     0.186848  \n",
       "3    -0.141962    -0.111375     0.104723     0.044907  \n",
       "4     0.035661     0.044390     0.051542     0.043067  \n",
       "\n",
       "[5 rows x 6651 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns_to_drop, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Data Split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df,stratify=df['label'],test_size=0.3, random_state=1729)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train['label']\n",
    "y_test = test['label']\n",
    "\n",
    "X_train = train.drop(['label', 'fileID'], axis=1)\n",
    "X_test = test.drop(['label', 'fileID'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SMOTE\n",
    "Citation:\n",
    "[1] N. V. Chawla, K. W. Bowyer, L. O. Hall, and W. P. Kegelmeyer, “SMOTE: Synthetic Minority Over-sampling Technique,” 1, vol. 16, pp. 321–357, Jun. 2002.\n",
    "\n",
    "_\"method of over-sampling the minority (abnormal) class and under-sampling the majority (normal) class can achieve better classifier performance (in ROC space) than only under-sampling the majority class. This paper also shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve better classifier performance (in ROC space) than varying the loss ratios in Ripper or class priors in Naive Bayes. Our method of over-sampling the minority class involves creating synthetic minority class examples.\"_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = SMOTE(random_state=1729, ratio = 1.0)\n",
    "X_train, y_train = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1322"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Classifiers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = []\n",
    "\n",
    "models.append((\"KNeighbors\",\n",
    "               KNeighborsClassifier(weights='distance')))\n",
    "\n",
    "models.append((\"LogisticRegression\",\n",
    "               LogisticRegression(solver='liblinear',\n",
    "                                  max_iter=1000000,\n",
    "                                  class_weight={1:.21},\n",
    "                                  penalty='l1')))\n",
    "\n",
    "dtBase = DecisionTreeClassifier(max_depth=10, \n",
    "                               max_features=9,\n",
    "                               class_weight={1:.2})\n",
    "\n",
    "models.append((\"DecisionTree\",dtBase))\n",
    "\n",
    "rdfBase = RandomForestClassifier(n_estimators=1000,\n",
    "                                class_weight={1:.2})\n",
    "\n",
    "models.append((\"RandomForest\",rdfBase))\n",
    "\n",
    "\n",
    "rf2 = RandomForestClassifier(n_estimators=1000, \n",
    "                             criterion='gini',\n",
    "                             max_depth=10,\n",
    "                             class_weight={1:.2})\n",
    "\n",
    "models.append((\"RandomForest-2\",rf2))\n",
    "\n",
    "models.append((\"BaggingClassifier\",\n",
    "               BaggingClassifier(DecisionTreeClassifier(max_depth=3),\n",
    "                                n_estimators=100,\n",
    "                                max_features=9)))\n",
    "\n",
    "models.append((\"BaggingClassifier-2\",\n",
    "               BaggingClassifier(dtBase,\n",
    "                                n_estimators=100,\n",
    "                                max_features=9)))\n",
    "\n",
    "models.append((\"AdaBoostClassifier\",\n",
    "               AdaBoostClassifier(DecisionTreeClassifier(max_depth=1),\n",
    "                                  algorithm=\"SAMME\",\n",
    "                                  n_estimators=1000)))\n",
    "\n",
    "models.append((\"GradientBoostingClassifier\",\n",
    "               GradientBoostingClassifier(n_estimators=100, \n",
    "                                          max_leaf_nodes=4, \n",
    "                                          max_depth = 10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-385c5682ea50>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# store models in a list, in case we want 'em again\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1463\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, self._rng,\n\u001b[1;32m   1464\u001b[0m                                     \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1465\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1467\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, X_val, y_val, sample_weight_val, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1527\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1528\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1529\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1530\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX_csr\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m             tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m-> 1194\u001b[0;31m                      check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1139\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1140\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    363\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 365\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "result_rows = []\n",
    "count = 1\n",
    "results_frame = pd.DataFrame()\n",
    "\n",
    "predictionsList = []\n",
    "fitted_models = []\n",
    "\n",
    "for name, model in models:\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # store models in a list, in case we want 'em again\n",
    "    fitted_models.append((name, model))\n",
    "    \n",
    "    # get predictions\n",
    "    prediction_vec = model.predict(X_test)\n",
    "    \n",
    "    # save predictions - useful for further ensemble methods/voters\n",
    "    predictionsList.append((name, prediction_vec))\n",
    "    \n",
    "#     # print a classifaction report for each model\n",
    "#     report = classification_report(y_test, prediction_vec)\n",
    "#     print(' #### ', name, '\\n', report, '\\n')\n",
    "    \n",
    "    # store result in data frame\n",
    "    results_frame.loc[count, 'Model'] = name\n",
    "    results_frame.loc[count, 'Accuracy'] = accuracy_score(y_test, prediction_vec)\n",
    "    results_frame.loc[count, 'Precision'] = precision_score(y_test, prediction_vec)\n",
    "    results_frame.loc[count, 'AUCROC'] = roc_auc_score(y_test, prediction_vec)\n",
    "\n",
    "    # increment data frame \n",
    "    count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add majority class classifier for base-line comparison\n",
    "majority_class = np.zeros(len(y_test))\n",
    "\n",
    "ac = accuracy_score(y_test, majority_class)\n",
    "pr = precision_score(y_test, majority_class)\n",
    "roc = roc_auc_score(y_test, majority_class)\n",
    "\n",
    "results_frame.loc[count, 'Model'] = 'Naive Baseline - MajorityClassClassifier'\n",
    "results_frame.loc[count, 'Accuracy'] = ac\n",
    "results_frame.loc[count, 'Precision'] = pr\n",
    "results_frame.loc[count, 'AUCROC'] = roc\n",
    "\n",
    "count = count + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_frame.head(len(results_frame))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network (to migrate to models)\n",
    "Neural Network Classifier Code (keras). No Need for it now, but may be useful in the event that BERT training time is too costly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape[1])\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=2)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = X_train.shape[1]\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "model.add(Dense(units=1000, activation='relu', input_dim=dim))\n",
    "model.add(Dense(units=5000, activation='softmax'))\n",
    "model.add(Dense(units=50, activation='relu'))\n",
    "# model.add(MaxPooling1D())\n",
    "# model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(Dense(units=50, activation='softmax'))\n",
    "model.add(Dense(units=5000, activation='relu'))\n",
    "model.add(Dense(units=2, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "#               optimizer=keras.optimizers.Adagrad(lr=0.0001),\n",
    "              metrics=['accuracy', \n",
    "                       custom_keras_metrics.keras_precision, \n",
    "                       custom_keras_metrics.keras_recall, \n",
    "                       custom_keras_metrics.keras_auc])\n",
    "\n",
    "# Train\n",
    "mod = model.fit(X_train, y_train, validation_data=(X_test,y_test), \n",
    "          epochs=20, batch_size=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(mod.history['keras_precision'])\n",
    "plt.plot(mod.history['val_keras_precision'])\n",
    "plt.title('model keras_precision')\n",
    "plt.ylabel('precision')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(mod.history['loss'])\n",
    "plt.plot(mod.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_frame.loc[count, 'Model'] = 'Simple ANN'\n",
    "results_frame.loc[count, 'Accuracy'] = mod.history['acc'][-1]\n",
    "results_frame.loc[count, 'Precision'] = mod.history['keras_precision'][-1]\n",
    "results_frame.loc[count, 'AUCROC'] = mod.history['val_keras_auc'][-1]\n",
    "\n",
    "results_frame.head(len(results_frame))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
